{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7038c9b",
   "metadata": {},
   "source": [
    "# A Minimal Toy Image Generator\n",
    "\n",
    "This file build a basic toy-data image generator based on flow-matching based method\n",
    "\n",
    "The file is adapted from the [mit diffusion model course](https://diffusion.csail.mit.edu/), and the repository is at [here](https://github.com/eje24/iap-diffusion-labs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf55fc1",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook implements a complete toy framework for flow matching, designed to visualize and test the behavior of learned vector fields between simple source and target distributions.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Part 1. Sampleable Distributions\n",
    "\n",
    "We define five configurable 2D distributions from which samples can be drawn:\n",
    " \n",
    "1. **Stretched Gaussian** — the 2-D Gaussian whose `$cov$` is not diagonal\n",
    "2. **Moons** — 2D crescent-shaped dataset.  \n",
    "3. **Checkerboard** — discrete alternating square pattern.  \n",
    "4. **Circles** — uniform distribution over a 2D circular region.\n",
    "\n",
    "Each batch is a tensor of shape `(batch_size, dim)`, where `dim = tunnel * Width * Height`.\n",
    "\n",
    "These images are in the floder `data`, and you can check that.\n",
    "\n",
    "The part 1 is just to make preparation -- to load in the data.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Part 2. Vector Field and Simulators\n",
    "\n",
    "Two numerical solvers are implemented to simulate trajectories based on learned vector fields:\n",
    "\n",
    "1. **Euler Method** — first-order integrator.  \n",
    "2. **Heun’s Method** — second-order integrator (improved Euler scheme).\n",
    "\n",
    "<br>\n",
    "\n",
    "### Part 3. Alpha/Beta and Conditional Vector Fields\n",
    "\n",
    "We define two classes of conditional vector fields parameterized by neural networks and constrained by:\n",
    "\n",
    "1. $ \\alpha(t)^2 + \\beta(t)^2 = 1 $  \n",
    "2. $ \\alpha(t) + \\beta(t) = 1 $\n",
    "\n",
    "These determine the blending between source and target scores in the learned velocity field.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Part 4. Neural Network Architecture and Package of Training Proess\n",
    "\n",
    "The core of the vector field $ u_\\theta(x, t) $ is a Multi-Layer Perceptron (MLP). The hidden structure is customizable.\n",
    "\n",
    "As for the training process:\n",
    "\n",
    "1. **Sample from Target and Time**: get $z$ from the data randomly get time $ts$\n",
    "2. **Sample from Source**: Draw base samples $ x_0 \\sim N(0, I_d) $, and based on $x_0$ and $ts$, calculute the $x_t$\n",
    "3. **Learn Vector Field**: Train $ u_\\theta $ to match source and target via flow matching loss.  \n",
    "\n",
    "<br>\n",
    "\n",
    "### Part 5. Training, Visualization and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478e982d",
   "metadata": {},
   "source": [
    "# Part 0: Basic Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1fefa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T16:50:42.942382Z",
     "iopub.status.busy": "2025-06-25T16:50:42.942067Z",
     "iopub.status.idle": "2025-06-25T16:50:45.720562Z",
     "shell.execute_reply": "2025-06-25T16:50:45.719886Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image       # Python Image Libiray (PIL)\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Dict, Type, Tuple\n",
    "from torch.func import vmap, jacrev\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"The device is: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6942bbb",
   "metadata": {},
   "source": [
    "# Part 1: Prepare Datasets and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb00d18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T16:50:45.722486Z",
     "iopub.status.busy": "2025-06-25T16:50:45.722320Z",
     "iopub.status.idle": "2025-06-25T16:50:45.725897Z",
     "shell.execute_reply": "2025-06-25T16:50:45.725552Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loads grayscale PNG images and returns them as tensors\n",
    "\n",
    "class ToyImageData(Dataset):\n",
    "    def __init__(self, root_dir: str, transform = None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform if transform else transforms.Compose([\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        self.image_files = sorted([\n",
    "            file for file in os.listdir(self.root_dir)\n",
    "            if file.endswith('.png')\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = os.path.join(self.root_dir, self.image_files[index])\n",
    "        image = Image.open(image_path).convert('L')                                 # L mode means the Gray image\n",
    "        image = self.transform(image)                                               # turn the image into the tensor\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59cd5c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T16:50:45.727518Z",
     "iopub.status.busy": "2025-06-25T16:50:45.727417Z",
     "iopub.status.idle": "2025-06-25T16:50:45.731307Z",
     "shell.execute_reply": "2025-06-25T16:50:45.731071Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets_checkerboard = ToyImageData(\"data/checkerboard\")\n",
    "dataloader_checkerboard = DataLoader(\n",
    "    dataset = datasets_checkerboard,\n",
    "    batch_size = 128,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "datasets_circles = ToyImageData(\"data/circles\")\n",
    "dataloader_circles = DataLoader(\n",
    "    dataset=datasets_circles,\n",
    "    batch_size=128,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "datasets_moons = ToyImageData(\"data/moons\")\n",
    "dataloader_moons = DataLoader(\n",
    "    dataset=datasets_moons,\n",
    "    batch_size=128,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "datasets_stretched_gaussian = ToyImageData(\"data/stretched_gaussian\")\n",
    "dataloader_stretched_gaussian = DataLoader(\n",
    "    dataset=datasets_stretched_gaussian,\n",
    "    batch_size=128,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadffedc",
   "metadata": {},
   "source": [
    "# Part 2: Vector Field and Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592acc15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T16:50:45.732471Z",
     "iopub.status.busy": "2025-06-25T16:50:45.732363Z",
     "iopub.status.idle": "2025-06-25T16:50:45.735919Z",
     "shell.execute_reply": "2025-06-25T16:50:45.735713Z"
    }
   },
   "outputs": [],
   "source": [
    "class VectorField(ABC):\n",
    "    @abstractmethod\n",
    "    def velocity(self, xt: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        # xt: shape(bs, dims), t: shape(bs, 1), returns: shape(bs, dims) where dims = channels * width * height\n",
    "        # return the speed velocity(xt, t) at position xt and time t\n",
    "        pass\n",
    "\n",
    "class Simulator(ABC):\n",
    "    @abstractmethod\n",
    "    def step(self, xt: torch.Tensor, t: torch.Tensor, h: torch.Tensor) -> torch.Tensor:\n",
    "        # xt: shape(bs, dims), t: shape(bs, 1), h: shape(bs, 1) (h and t should be board cast form shape(,))\n",
    "        # return the state at t + h\n",
    "        pass\n",
    "\n",
    "    def simulate(self, x: torch.Tensor, ts: torch.Tensor) -> torch.Tensor:\n",
    "        # x: shape(bs, dims), ts: shape(num_ts,)\n",
    "        # put in the state at ts[0], return the state at ts[-1]\n",
    "        for index in range(ts.shape[0] - 1):\n",
    "            t = ts[index].expand(x.shape[0], 1)\n",
    "            h = (ts[index+1] - ts[index]).expand(x.shape[0], 1)\n",
    "            x = self.step(x, t, h)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class EulerSimulator(Simulator):\n",
    "    def __init__(self, vector_field: VectorField):\n",
    "        self.vector_field = vector_field\n",
    "\n",
    "    def step(self, xt: torch.Tensor, t: torch.Tensor, h: torch.Tensor) -> torch.Tensor:\n",
    "        return xt + self.vector_field.velocity(xt, t) * h\n",
    "    \n",
    "class HenuSimulator(Simulator):\n",
    "    def __init__(self, vector_field: VectorField):\n",
    "        self.vector_field = vector_field\n",
    "\n",
    "    def step(self, xt: torch.Tensor, t: torch.Tensor, h: torch.Tensor) -> torch.Tensor:\n",
    "        x_euler = xt + self.vector_field.velocity(xt, t) * h\n",
    "        return xt + 0.5 * (self.vector_field.velocity(xt, t) + self.vector_field.velocity(x_euler, t + h)) * h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64262287",
   "metadata": {},
   "source": [
    "# Part 3: Alpha, Beta and the Conditional Vector Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8866ca",
   "metadata": {},
   "source": [
    "#### 1. Gaussian conditional probability path:    \n",
    "\n",
    "A Gaussian conditional probability path is given by\n",
    "\n",
    "$$p_t(x|z) = N(x;\\alpha_t z,\\beta_t^2 I_d),\\quad\\quad\\quad p_{\\text{simple}}=N(0,I_d),$$\n",
    "\n",
    "where $\\alpha_t: [0,1] \\to \\mathbb{R}$ and $\\beta_t: [0,1] \\to \\mathbb{R}$ are monotonic, continuously differentiable functions satisfying $\\alpha_1 = \\beta_0 = 1$ and $\\alpha_0 = \\beta_1 = 0$. \n",
    "\n",
    "In other words, this implies that $p_1(x|z) = \\delta_z$ and $p_0(x|z) = N(0, I_d)$ is a unit Gaussian. Before we dive into things, let's take a look at $p_{\\text{simple}}$ and $p_{\\text{data}}$. \n",
    "\n",
    "And simply,\n",
    "\n",
    "$$X_{t | z} = \\alpha_t z + \\beta_t X_0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c90c838",
   "metadata": {},
   "source": [
    "In this section, we'll be using \n",
    "\n",
    "$$\\alpha_t = t \\quad \\quad \\text{and} \\quad \\quad \\beta_t = 1-t.$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\alpha_t = t \\quad \\quad \\text{and} \\quad \\quad \\beta_t = \\sqrt{1-t}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f8600",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T16:50:45.737234Z",
     "iopub.status.busy": "2025-06-25T16:50:45.737119Z",
     "iopub.status.idle": "2025-06-25T16:50:45.743476Z",
     "shell.execute_reply": "2025-06-25T16:50:45.743145Z"
    }
   },
   "outputs": [],
   "source": [
    "class Alpha(ABC):\n",
    "    def __init__(self, eps: float = 1e-8):\n",
    "        self.eps = eps\n",
    "        assert torch.allclose(self(torch.zeros(1, 1)), torch.zeros(1, 1), atol=math.sqrt(self.eps))\n",
    "        assert torch.allclose(self(torch.ones(1, 1)), torch.ones(1, 1))\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        # t: shape(bs, 1), or fundamentally, shape(1, 1), returns: shape(bs, 1), or fundamentally, shape(1, 1)\n",
    "        pass\n",
    "\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        # t: shape(bs, 1) or fundatmentally, (1, 1), returns: shape(bs, 1) or (1, 1)\n",
    "        return vmap(jacrev(self)) (t)\n",
    "    \n",
    "class Beta(ABC):\n",
    "    def __init__(self, eps: float = 1e-8):\n",
    "        self.eps = eps\n",
    "        assert torch.allclose(self(torch.zeros(1, 1)), torch.ones(1, 1))\n",
    "        assert torch.allclose(self(torch.ones(1, 1)), torch.zeros(1, 1), atol=math.sqrt(self.eps))\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, t) -> torch.Tensor:\n",
    "        pass\n",
    "\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return vmap(jacrev(self)) (t)\n",
    "    \n",
    "class LinearAlpha(Alpha):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return t\n",
    "    \n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.ones_like(t)\n",
    "    \n",
    "class LinearBeta(Beta):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return 1 - t\n",
    "    \n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return - torch.ones_like(t)\n",
    "    \n",
    "class SquareRootBeta(Beta):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.sqrt(torch.clamp(1 - t, min=self.eps))\n",
    "    \n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return -0.5 / torch.sqrt(torch.clamp(1 - t, min=self.eps))\n",
    "    \n",
    "alpha_linear = LinearAlpha()\n",
    "beta_linear = LinearBeta()\n",
    "beta_sqrt = SquareRootBeta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e9c8b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T16:50:45.744992Z",
     "iopub.status.busy": "2025-06-25T16:50:45.744845Z",
     "iopub.status.idle": "2025-06-25T16:50:45.749136Z",
     "shell.execute_reply": "2025-06-25T16:50:45.748706Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConditionalVectorField(ABC):\n",
    "    @abstractmethod\n",
    "    def velocity(self, xt: torch.Tensor, t: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
    "        # xt: shape(bs, dims), t: shape(bs, 1), z: shape(bs, dims) where dims = channels * width * height\n",
    "        # at time t and position xt, given z, return the velocity veccity(xt, t, z)\n",
    "        pass\n",
    "\n",
    "class GaussianConditionalVectorField(ConditionalVectorField):\n",
    "    def __init__(self, alpha: Alpha, beta: Beta):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def velocity(self, xt: torch.Tensor, t: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
    "        alpha_d_t, beta_d_t = self.alpha.dt(t), self.beta.dt(t)\n",
    "        alpha_t, beta_t = self.alpha(t), self.beta(t)\n",
    "        return (alpha_d_t - beta_d_t * alpha_t / beta_t) * z + beta_d_t / beta_t * xt\n",
    "    \n",
    "gaussian_conditional_vector_field_linear = GaussianConditionalVectorField(alpha=alpha_linear, beta=beta_linear)\n",
    "gaussian_conditional_vector_field_sqrt = GaussianConditionalVectorField(alpha=alpha_linear, beta=beta_sqrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fa8229",
   "metadata": {},
   "source": [
    "# Part 4: NN and Train classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2b58a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T16:50:45.751398Z",
     "iopub.status.busy": "2025-06-25T16:50:45.751033Z",
     "iopub.status.idle": "2025-06-25T16:50:45.880238Z",
     "shell.execute_reply": "2025-06-25T16:50:45.879937Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_mlp(dims: List[int], activation: Type[nn.Module] = nn.SiLU):\n",
    "    mlp = []\n",
    "    for index in range(len(dims) - 1):\n",
    "        mlp.append(nn.Linear(dims[index], dims[index+1]))\n",
    "        if index < len(dims) - 2:\n",
    "            mlp.append(activation())\n",
    "    return nn.Sequential(*mlp)\n",
    "\n",
    "class MLPVectorField(nn.Module):\n",
    "    def __init__(self, dim: int = 1 * 64 * 64, hiddens: List[int] = [2048, 512, 256], activation = None):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.mlp = make_mlp([dim+1] + hiddens + [dim], activation) if activation else make_mlp([dim+1] + hiddens + [dim])\n",
    "\n",
    "    def forward(self, xt: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        # xt: shape(bs, dims), t: shape(bs, 1)\n",
    "        input = torch.cat([xt, t], dim=-1)\n",
    "        return self.mlp(input)\n",
    "    \n",
    "mlp_stretched_gaussian = MLPVectorField()\n",
    "mlp_moons = MLPVectorField()\n",
    "mlp_circles = MLPVectorField()\n",
    "mlp_checkerboard = MLPVectorField()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81776da",
   "metadata": {},
   "source": [
    "Recall now that from lecture that our goal is to learn the *marginal vector field* $u_t(x)$ given by \n",
    "\n",
    "$$u_t^{\\text{ref}}(x) = \\mathbb{E}_{z \\sim p_t(z|x)}\\left[u_t^{\\text{ref}}(x|z)\\right].$$\n",
    "\n",
    "Unfortunately, we don't actually know what $u_t^{\\text{ref}}(x)$ is! \n",
    "\n",
    "We will thus approximate $u_t^{\\text{ref}}(x)$ as a neural network $u_t^{\\theta}(x)$, and exploit the identity \n",
    "\n",
    "$$ u_t^{\\text{ref}}(x) = \\text{argmin}_{u_t(x)} \\,\\,\\mathbb{E}_{z \\sim p_t(z|x)} \\left[\\lVert u_t(x) - u_t^{\\text{ref}}(x|z)\\rVert^2\\right]$$ \n",
    "\n",
    "to obtain the **conditional flow matching objective**\n",
    "\n",
    "$$ \\mathcal{L}_{\\text{CFM}}(\\theta) = \\,\\,\\mathbb{E}_{z \\sim p(z), x \\sim p_t(x|z)} \\left[\\lVert u_t^{\\theta}(x) - u_t^{\\text{ref}}(x|z)\\rVert^2\\right].$$\n",
    "\n",
    "To model $u_t^{\\theta}(x)$, we'll use a simple MLP. This network will take in both $x$ and $t$, and will return the learned vector field $u_t^{\\theta}(x)$.\n",
    "\n",
    "\n",
    "We simulate the loss function: \n",
    "\n",
    "$$\\mathcal{L}_{\\text{CFM}}(\\theta) = \\,\\,\\mathbb{E}_{{t \\in \\mathcal{U}[0,1), z \\sim p(z), x \\sim p_t(x|z)}} {\\lVert u_t^{\\theta}(x) - u_t^{\\text{ref}}(x|z)\\rVert^2}$$\n",
    "\n",
    "using a Monte-Carlo estimate of the form\n",
    "\n",
    "$$\\frac{1}{N}\\sum_{i=1}^N {\\lVert u_{t_i}^{\\theta}(x_i) - u_{t_i}^{\\text{ref}}(x_i|z_i)\\rVert^2}, \\quad \\quad \\quad \\forall i\\in[1, \\dots, N]: {\\,z_i \\sim p_{\\text{data}},\\, t_i \\sim \\mathcal{U}[0,1),\\, x_i \\sim p_t(\\cdot | z_i)}.$$\n",
    "\n",
    "Here, $N$ is our *batch size*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa91b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T16:50:45.881636Z",
     "iopub.status.busy": "2025-06-25T16:50:45.881553Z",
     "iopub.status.idle": "2025-06-25T16:50:45.885521Z",
     "shell.execute_reply": "2025-06-25T16:50:45.885134Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLPGaussianTrainer():\n",
    "    def __init__(self, u_theta: MLPVectorField, u_cond: GaussianConditionalVectorField, dataloader: DataLoader, save_addr: str = None):\n",
    "        self.u_theta = u_theta\n",
    "        self.u_cond = u_cond\n",
    "        self.dataloader = dataloader\n",
    "        if save_addr:\n",
    "            if not save_addr.endswith(\"pth\"):\n",
    "                save_addr += \"pth\"\n",
    "        else: \n",
    "            save_addr = \"mlp_parameters.pth\"\n",
    "        self.save_addr = save_addr\n",
    "\n",
    "    def get_optimizer(self, lr: float = 1e-4):\n",
    "        return torch.optim.Adam(self.u_theta.parameters(), lr=lr)\n",
    "    \n",
    "    def get_loss(self, xt: torch.Tensor, t: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
    "        # xt: shape(bs, dims), t: shape(bs, 1)\n",
    "\n",
    "        # velocity: shape(bs, dims)\n",
    "        velocity_cond = self.u_cond.velocity(xt, t, z)\n",
    "        velocity_mlp = self.u_theta(xt, t)\n",
    "\n",
    "        errors = torch.sum((velocity_cond - velocity_mlp) ** 2, dim=-1)\n",
    "        return torch.mean(errors)\n",
    "\n",
    "    def train(self, device: torch.device, num_epochs: int = 50000, lr: float = 1e-4, loss_image_name: str = None):\n",
    "        # make preparation\n",
    "        self.u_theta.to(device)\n",
    "        self.u_theta.train()\n",
    "        optimizer = self.get_optimizer(lr=lr)\n",
    "        losses = []\n",
    "        \n",
    "        # train process\n",
    "        pbr = tqdm(range(num_epochs))\n",
    "        for epoch in pbr:\n",
    "            total_loss = 0.0\n",
    "            for batch in self.dataloader:\n",
    "                z = batch.to(device).view(batch.shape[0], -1)           # z: shape(bs, dims)\n",
    "\n",
    "                t = torch.rand(z.shape[0], 1).to(device)                     # t: shape(bs, 1)\n",
    "  \n",
    "                x_init = torch.randn_like(z).to(device)                        # xt: shape(bs, dims)\n",
    "                xt = self.u_cond.alpha(t) * z + self.u_cond.beta(t) * x_init\n",
    "\n",
    "                loss = self.get_loss(xt, t, z)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "            pbr.set_description(f\"Epoch {epoch}, the loss is: {total_loss}\")\n",
    "            losses.append(total_loss)\n",
    "\n",
    "        self.u_theta.eval()\n",
    "\n",
    "        # visualize the loss curve\n",
    "        plt.plot(losses)\n",
    "        plt.title(\"Training Loss Curve\")\n",
    "        plt.xlabel(\"num_epochs\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.grid(True)\n",
    "\n",
    "        if loss_image_name is not None:\n",
    "            os.makedirs(os.path.dirname(loss_image_name), exist_ok=True)\n",
    "            plt.savefig(loss_image_name, bbox_inches='tight', pad_inches=0, dpi=300)\n",
    "            print(f\"Loss curve saved to: {loss_image_name}\")\n",
    "        plt.show()\n",
    "\n",
    "        # save the parameters\n",
    "        torch.save(self.u_theta.state_dict(), self.save_addr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc485f35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T16:50:45.886766Z",
     "iopub.status.busy": "2025-06-25T16:50:45.886670Z",
     "iopub.status.idle": "2025-06-25T16:50:45.889229Z",
     "shell.execute_reply": "2025-06-25T16:50:45.888982Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer_stretched_gaussian = MLPGaussianTrainer(\n",
    "    u_theta = mlp_stretched_gaussian,\n",
    "    u_cond = gaussian_conditional_vector_field_linear,\n",
    "    dataloader = dataloader_stretched_gaussian,\n",
    "    save_addr = \"to_stretched_gaussian_mlp.pth\"\n",
    ")\n",
    "\n",
    "trainer_moons = MLPGaussianTrainer(\n",
    "    u_theta = mlp_moons,\n",
    "    u_cond = gaussian_conditional_vector_field_linear,\n",
    "    dataloader = dataloader_moons,\n",
    "    save_addr = \"to_moons_mlp.pth\"\n",
    ")\n",
    "\n",
    "trainer_circles = MLPGaussianTrainer(\n",
    "    u_theta = mlp_circles,\n",
    "    u_cond = gaussian_conditional_vector_field_linear,\n",
    "    dataloader = dataloader_circles,\n",
    "    save_addr = \"to_circles_mlp.pth\"\n",
    ")\n",
    "\n",
    "trainer_checkerboard = MLPGaussianTrainer(\n",
    "    u_theta = mlp_checkerboard,\n",
    "    u_cond = gaussian_conditional_vector_field_linear,\n",
    "    dataloader = dataloader_checkerboard,\n",
    "    save_addr = \"to_checkerboard_mlp.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e06e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T16:50:45.890611Z",
     "iopub.status.busy": "2025-06-25T16:50:45.890492Z",
     "iopub.status.idle": "2025-06-25T16:50:45.892186Z",
     "shell.execute_reply": "2025-06-25T16:50:45.891890Z"
    }
   },
   "outputs": [],
   "source": [
    "class LearnedVectorField(VectorField):\n",
    "    def __init__(self, model: MLPVectorField):\n",
    "        self.model = model\n",
    "\n",
    "    def velocity(self, xt: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(xt, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c78b1e2",
   "metadata": {},
   "source": [
    "# Part 5: Training, Evaluation and visluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6ca2e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T16:50:45.894019Z",
     "iopub.status.busy": "2025-06-25T16:50:45.893793Z",
     "iopub.status.idle": "2025-06-25T16:50:45.896323Z",
     "shell.execute_reply": "2025-06-25T16:50:45.896103Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_generated_tensor(tensor: torch.Tensor, title: str = \"Generated Image\", save_path: str = None):\n",
    "    \"\"\"\n",
    "    - tensor: shape = (4096,) → reshape to (64, 64), and visualize it as grayscale image.\n",
    "    - save_path: if provided, saves the image to this file path.\n",
    "    \"\"\"\n",
    "    if tensor.ndim != 1 or tensor.shape[0] != 4096:\n",
    "        raise ValueError(f\"Expected tensor of shape (4096,), got {tensor.shape}\")\n",
    "\n",
    "    image = tensor.detach().cpu().view(64, 64)  # reshape\n",
    "    image = torch.clamp(image, 0.0, 1.0)        # ensure range in [0, 1]\n",
    "\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "    if save_path is not None:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n",
    "        print(f\"Image saved to: {save_path}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f1f932",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T16:50:45.897735Z",
     "iopub.status.busy": "2025-06-25T16:50:45.897589Z",
     "iopub.status.idle": "2025-06-25T16:50:45.952590Z",
     "shell.execute_reply": "2025-06-25T16:50:45.952219Z"
    }
   },
   "outputs": [],
   "source": [
    "x_init = torch.randn(1,4096).to(device)\n",
    "ts = torch.linspace(0.0, 1.0, 500).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb6f3b0",
   "metadata": {},
   "source": [
    "### 1. Moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7facc627",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T16:50:45.953816Z",
     "iopub.status.busy": "2025-06-25T16:50:45.953726Z",
     "iopub.status.idle": "2025-06-25T18:06:06.854012Z",
     "shell.execute_reply": "2025-06-25T18:06:06.853696Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer_moons.train(device=device, loss_image_name=\"loss_analysis/moons.png\")\n",
    "\n",
    "vector_field_moons = LearnedVectorField(model=mlp_moons)\n",
    "euler_moons = EulerSimulator(vector_field=vector_field_moons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd7e7ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T18:06:06.855450Z",
     "iopub.status.busy": "2025-06-25T18:06:06.855344Z",
     "iopub.status.idle": "2025-06-25T18:06:06.987692Z",
     "shell.execute_reply": "2025-06-25T18:06:06.985494Z"
    }
   },
   "outputs": [],
   "source": [
    "generated_moons = euler_moons.simulate(x_init, ts).squeeze()\n",
    "visualize_generated_tensor(tensor=generated_moons, title=\"Moons\", save_path=\"generated/Moons.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020d65f0",
   "metadata": {},
   "source": [
    "### 2. Circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3b7835",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T18:06:06.988879Z",
     "iopub.status.busy": "2025-06-25T18:06:06.988811Z",
     "iopub.status.idle": "2025-06-25T19:23:20.725265Z",
     "shell.execute_reply": "2025-06-25T19:23:20.724921Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer_circles.train(device=device, loss_image_name=\"loss_analysis/circles.png\")\n",
    "\n",
    "vector_field_circles = LearnedVectorField(model=mlp_circles)\n",
    "euler_circles = EulerSimulator(vector_field=vector_field_circles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb5105f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T19:23:20.726838Z",
     "iopub.status.busy": "2025-06-25T19:23:20.726765Z",
     "iopub.status.idle": "2025-06-25T19:23:20.855763Z",
     "shell.execute_reply": "2025-06-25T19:23:20.854816Z"
    }
   },
   "outputs": [],
   "source": [
    "generated_circles = euler_circles.simulate(x_init, ts).squeeze()\n",
    "visualize_generated_tensor(tensor=generated_circles, title=\"Circles\", save_path=\"generated/Circles.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e38d1a1",
   "metadata": {},
   "source": [
    "### 3. Checkerboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a7cb66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T19:23:20.857752Z",
     "iopub.status.busy": "2025-06-25T19:23:20.857381Z",
     "iopub.status.idle": "2025-06-25T20:35:07.531114Z",
     "shell.execute_reply": "2025-06-25T20:35:07.530783Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer_checkerboard.train(device=device, loss_image_name=\"loss_analysis/checkerboard.png\")\n",
    "\n",
    "vector_field_checkerboard = LearnedVectorField(model=mlp_checkerboard)\n",
    "euler_circles = EulerSimulator(vector_field=vector_field_checkerboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbb6c6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T20:35:07.532790Z",
     "iopub.status.busy": "2025-06-25T20:35:07.532696Z",
     "iopub.status.idle": "2025-06-25T20:35:07.659793Z",
     "shell.execute_reply": "2025-06-25T20:35:07.659330Z"
    }
   },
   "outputs": [],
   "source": [
    "generated_checkerboard = euler_circles.simulate(x_init, ts).squeeze()\n",
    "visualize_generated_tensor(tensor=generated_checkerboard, title=\"Checkerboard\", save_path=\"generated/Checkerboard.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca0d8b8",
   "metadata": {},
   "source": [
    "### 4. Stretched Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d999cf13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T20:35:07.661067Z",
     "iopub.status.busy": "2025-06-25T20:35:07.660983Z",
     "iopub.status.idle": "2025-06-25T21:51:37.835375Z",
     "shell.execute_reply": "2025-06-25T21:51:37.835031Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer_stretched_gaussian.train(device=device, loss_image_name=\"loss_analysis/stretched_gaussian.png\")\n",
    "\n",
    "vector_field_stretched_gaussian = LearnedVectorField(model=mlp_stretched_gaussian)\n",
    "euler_stretched_gaussian = EulerSimulator(vector_field=vector_field_stretched_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fe2330",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T21:51:37.836847Z",
     "iopub.status.busy": "2025-06-25T21:51:37.836779Z",
     "iopub.status.idle": "2025-06-25T21:51:37.964172Z",
     "shell.execute_reply": "2025-06-25T21:51:37.963792Z"
    }
   },
   "outputs": [],
   "source": [
    "generated_stretched_gaussian = euler_stretched_gaussian.simulate(x_init, ts).squeeze()\n",
    "visualize_generated_tensor(tensor=generated_stretched_gaussian, title=\"Stretched Gaussian\", save_path=\"generated/Stretched_Gaussian.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
