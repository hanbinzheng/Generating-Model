{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "485ab646",
   "metadata": {},
   "source": [
    "# Generate MNIST and CIFAR10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26ab20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Optional, List, Type, Tuple, Dict\n",
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.axes._axes import Axes\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions as D\n",
    "from torch.func import vmap, jacrev\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_moons, make_circles\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7a5a87",
   "metadata": {},
   "source": [
    "## Part 1: Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99853662",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampleable(ABC):\n",
    "    # distributions to be sampled from\n",
    "    def sample(self, num_samples: int) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - num_samples: the desired number of samples\n",
    "        Returns:\n",
    "            - samples: shape (batch_size, ...)\n",
    "            - labels: shape (batch_size,)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "class IsotropicGaussian(nn.Module, Sampleable):\n",
    "    def __init__(self, shape: List[int], std: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "        self.std = std\n",
    "        self.dummy = nn.Buffer(torch.zeros(1))\n",
    "\n",
    "    def sample(self, num_samples) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
    "        return self.std * torch.randn(num_samples, *self.shape).to(self.dummy.device), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7346e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTSampler(nn.Module, Sampleable):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dataset = datasets.MNIST(\n",
    "            root = \"./data_mnist\",\n",
    "            train = True,\n",
    "            download = True,\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize((32, 32)),\n",
    "                transforms.ToTensor(),                              # to tensor of [0, 1]\n",
    "                transforms.Normalize(mean=(0.5, ), std=(0.5, ))     # (x - 0.5) / 0.5 = 2x - 1 [-1, 1]\n",
    "            ])\n",
    "        )\n",
    "        self.dummy = nn.Buffer(torch.zeros(1))\n",
    "\n",
    "    def sample(self, num_samples: int) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
    "        indices = torch.randperm(len(self.dataset))[:num_samples]\n",
    "        samples, labels = zip(*[self.dataset[i] for i in indices])\n",
    "        samples = torch.stack(samples).to(self.dummy.device)\n",
    "        labels = torch.tensor(labels).to(self.dummy.device)\n",
    "        return samples, labels\n",
    "\n",
    "mnist_sampler = MNISTSampler()\n",
    "mnist_images, mnist_label = mnist_sampler.sample(15)                  # [-1, 1]\n",
    "mnist_images = (1 + mnist_images) / 2                                 # [0, 1] so that make_grid can handle it correctly\n",
    "mnist_grid_image = make_grid(mnist_images, nrow=15)\n",
    "mnist_grid_image = mnist_grid_image.permute(1, 2, 0).cpu().numpy()\n",
    "plt.figure(figsize=(1 * 15, 1))\n",
    "plt.imshow(mnist_grid_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045f679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Sampler(nn.Module, Sampleable):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dataset = datasets.CIFAR10(\n",
    "            root = \"./data_cifar10\",\n",
    "            train = True,\n",
    "            download = True,\n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "            ])\n",
    "        )\n",
    "        self.dummy = nn.Buffer(torch.zeros(1))\n",
    "    \n",
    "    def sample(self, num_samples: int) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
    "        indices = torch.randperm(len(self.dataset))[:num_samples]\n",
    "        samples, labels = zip(*[self.dataset[i] for i in indices])\n",
    "        samples = torch.stack(samples).to(self.dummy.device)\n",
    "        labels = torch.tensor(labels).to(self.dummy.device)\n",
    "        return samples, labels\n",
    "    \n",
    "cifar10_sampler = CIFAR10Sampler()\n",
    "cifar10_images, cifar10_labels = cifar10_sampler.sample(15)\n",
    "cifar10_images = (1 + cifar10_images) / 2\n",
    "cifar10_grid_image = make_grid(cifar10_images, nrow=15)\n",
    "cifar10_grid_image = cifar10_grid_image.permute(1, 2, 0).cpu().numpy()\n",
    "plt.figure(figsize=(1 * 15, 1))\n",
    "plt.imshow(cifar10_grid_image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62797e39",
   "metadata": {},
   "source": [
    "## Part 2: Probability Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e47480",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalProbabilityPath(nn.Module, ABC):\n",
    "    def __init__(self, p_simple: Sampleable, p_data: Sampleable):\n",
    "        super().__init__()\n",
    "        self.p_simple = p_simple\n",
    "        self.p_data = p_data\n",
    "\n",
    "    def sample_conditioning_variable(self, num_samples: int) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
    "        # returns: z, y = shape(num_samples, c, h, w), shape(num_samples, )\n",
    "        return self.p_data.sample(num_samples)\n",
    "\n",
    "    @abstractmethod\n",
    "    def sample_conditional_path(self, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        # get position form the p_t(x|z), z: shape(bs, c, h, w), t: shape(bs, 1, 1, 1)\n",
    "        # returns: shape(bs, c, h, w)\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def conditional_vector_field(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        # get the velocity given position x, condition z and time t\n",
    "        # x: shape(bs, c, h, w), z: shape(bs, c, h, w), t: shape(bs, 1, 1, 1)\n",
    "        # returns: shape(bs, c, h, w)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a56f12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alpha(ABC):\n",
    "    def __init__(self):\n",
    "        assert torch.allclose(self(torch.zeros(1, 1, 1, 1)), torch.zeros(1, 1, 1, 1))\n",
    "        assert torch.allclose(self(torch.ones(1, 1, 1, 1)), torch.ones(1, 1, 1, 1))\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        pass\n",
    "\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return (vmap(jacrev(self)) (t.unsqueeze(1))).view(-1, 1, 1, 1)\n",
    "    \n",
    "class Beta(ABC):\n",
    "    def __init__(self):\n",
    "        assert torch.allclose(self(torch.zeros(1, 1, 1, 1)), torch.ones(1, 1, 1, 1))\n",
    "        assert torch.allclose(self(torch.ones(1, 1, 1, 1)), torch.zeros(1, 1, 1, 1))\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        pass\n",
    "\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return (vmap(jacrev(self)) (t.unsqueeze(1))).view(-1, 1, 1, 1)\n",
    "    \n",
    "class LinearAlpha(Alpha):\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        # t: shape(num_samples, 1, 1, 1)\n",
    "        return t\n",
    "    \n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        # t: shape(num_samples, 1, 1, 1)\n",
    "        return torch.ones_like(t)\n",
    "    \n",
    "class LinearBeta(Beta):\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        # t: shape(num_samples, 1, 1, 1)\n",
    "        return 1 - t\n",
    "    \n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        # t: shape(num_samples, 1, 1, 1)\n",
    "        return - torch.ones_like(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bbb807",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianConditionalProbabilityPath(ConditionalProbabilityPath):\n",
    "    def __init__(self, p_data: Sampleable, p_simple_shape: List[int], alpha: Alpha, beta: Beta):\n",
    "        p_simple = IsotropicGaussian(shape=p_simple_shape, std=1.0)\n",
    "        super().__init__(p_data=p_data, p_simple=p_simple)\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "    \n",
    "    def sample_conditional_path(self, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        # z: shape(bs, c, h, w), t: shape(bs, 1, 1, 1)\n",
    "        return self.alpha(t) * z + self.beta(t) * torch.randn_like(z)\n",
    "\n",
    "    def conditional_vector_field(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        # x: shape(bs, c, h, w), z: shape(bs, c, h, w), t: shape(bs, 1, 1, 1)\n",
    "        alpha_t = self.alpha(t)         # (bs, 1, 1, 1)\n",
    "        beta_t = self.beta(t)           # (bs, 1, 1, 1)\n",
    "        dt_alpha_t = self.alpha.dt(t)   # (bs, 1, 1, 1)\n",
    "        dt_beta_t = self.beta.dt(t)     # (bs, 1, 1, 1)\n",
    "\n",
    "        return (dt_alpha_t - dt_beta_t / beta_t * alpha_t) * z + dt_beta_t / beta_t * x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da911a1",
   "metadata": {},
   "source": [
    "## Part 3: Vector Field and Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018e20fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorField(ABC): \n",
    "    @abstractmethod\n",
    "    def velocity(self, xt: torch.Tensor, t: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "        # xt: the position at time t, shape(bs, c, h, w); t: shape(bs, 1, 1, 1)\n",
    "        pass\n",
    "\n",
    "class NNVectorField(nn.Module, ABC):\n",
    "    @abstractmethod\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        # returns u_t^theta(x | y), shape(bs, c, h, w)\n",
    "        pass\n",
    "\n",
    "class CFGVectorField(VectorField):\n",
    "    def __init__(self, net: NNVectorField, guidance_scale: float = 1.0):\n",
    "        self.net = net\n",
    "        self.guidance_scale = guidance_scale\n",
    "\n",
    "    def velocity(self, xt: torch.Tensor, t: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        guided_velocity = self.net(xt, t, y)\n",
    "        unguided_y = torch.ones_like(y) * 10\n",
    "        unguided_velocity = self.net(xt, t, unguided_y)\n",
    "        return self.guidance_scale * guided_velocity + (1 - self.guidance_scale) * unguided_velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ad0887",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator(ABC):\n",
    "    @abstractmethod\n",
    "    def step(self, xt: torch.Tensor, t: torch.Tensor, dt: torch.Tensor, **kwargs):\n",
    "        # xt: shape(bs, c, h, w), t: shape(bs, 1, 1, 1), dt: shape(bs, 1, 1, 1)\n",
    "        pass\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def simulate(self, x: torch.Tensor, ts: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "        # x_init: shape(bs, c, h, w), ts: shape(bs, nts, 1, 1, 1), returns: shape(bs, c, h, w)\n",
    "        nts = ts.shape[1]\n",
    "        for t_idx in tqdm(range(nts - 1)):\n",
    "            t = ts[:, t_idx]\n",
    "            h = ts[:, t_idx + 1] - ts[:, t_idx]\n",
    "            x = self.step(x, t, h, **kwargs)\n",
    "        return x\n",
    "    \n",
    "class EulerSimulator(Simulator):\n",
    "    def __init__(self, vector_field: VectorField):\n",
    "        self.vector_field = vector_field\n",
    "    \n",
    "    def step(self, xt: torch.Tensor, t: torch.Tensor, dt: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "        return xt + self.vector_field.velocity(xt, t, **kwargs) * dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c16b7c",
   "metadata": {},
   "source": [
    "## Part 4: NN Struture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5e3707",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierEncoder(nn.Module):\n",
    "    def __init__(self, dim: int):\n",
    "        super().__init__()\n",
    "        assert dim % 2 == 0\n",
    "        self.half_dim = dim // 2\n",
    "        self.freqs = nn.Parameter(torch.randn(1, self.half_dim))        # shape(1, half_dim)\n",
    "\n",
    "    def forward(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        # t: shape(bs, 1, 1, 1)\n",
    "        t = t.view(-1, 1)                                               # shape(bs, 1)\n",
    "        theta = t * self.freqs * 2 * math.pi                            # shape(bs, half_dim)\n",
    "        sin_embed = torch.sin(theta)                                    # shape(bs, half_dim)\n",
    "        cos_embed = torch.cos(theta)                                    # shape(bs, half_dim)\n",
    "        return torch.cat([sin_embed, cos_embed], dim=-1) * math.sqrt(2) # shape(bs, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3eccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptLayer(nn.Module):\n",
    "    def __init__(self, channels: int, t_embed_dim: int, y_embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.BatchNorm2d(num_features=channels),\n",
    "            nn.Conv2d(in_channels=channels, out_channels=channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.BatchNorm2d(num_features=channels),\n",
    "            nn.Conv2d(in_channels=channels, out_channels=channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.t_adapter = nn.Sequential(\n",
    "            nn.Linear(t_embed_dim, t_embed_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(t_embed_dim, channels)\n",
    "        )\n",
    "        self.y_adapter = nn.Sequential(\n",
    "            nn.Linear(y_embed_dim, y_embed_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(y_embed_dim, channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, t_embed: torch.Tensor, y_embed: torch.Tensor) -> torch.Tensor:\n",
    "        # x: shape(bs, c, h, w), t_embed: shape(bs, t_embed_dim), y_embed: shape(bs, y_embed_dim)\n",
    "        x_origin = x.clone()\n",
    "        x = self.block1(x)\n",
    "\n",
    "        t_adapted = self.t_adapter(t_embed).unsqueeze(-1).unsqueeze(-1)     # shape(bs, c, 1, 1)\n",
    "        x += t_adapted\n",
    "        y_adapted = self.y_adapter(y_embed).unsqueeze(-1).unsqueeze(-1)     # shape(bs, c, 1, 1)\n",
    "        x += y_adapted\n",
    "\n",
    "        x = self.block2(x)                                                  # shape(bs, c, h, w)\n",
    "        x += x_origin\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc8b644",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, channels_in: int, channels_out: int, num_adapt_layer: int, t_embed_dim: int, y_embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.adapt_blocks = nn.ModuleList([\n",
    "            AdaptLayer(channels=channels_in, t_embed_dim=t_embed_dim, y_embed_dim=y_embed_dim) for _ in range(num_adapt_layer)\n",
    "        ])\n",
    "        self.downsample = nn.Conv2d(in_channels=channels_in, out_channels=channels_out, kernel_size=3, stride=2, padding=1)\n",
    "        # out_dim = floor((in_dim + 2 * padding - kernel_size + 1) / stride) = floor(in_dim / 2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t_embed: torch.Tensor, y_embed: torch.Tensor) -> torch.Tensor:\n",
    "        # x: shape(bs, c, h, w), t_embed: shape(bs, t_embed_dim), y_embed: shape(bs, y_embed_dim)\n",
    "        for block in self.adapt_blocks:\n",
    "            x = block(x, t_embed, y_embed)\n",
    "        x = self.downsample(x)\n",
    "        return x\n",
    "    \n",
    "class Midcoder(nn.Module):\n",
    "    def __init__(self, channels: int, num_adapt_layer: int, t_embed_dim: int, y_embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.adapt_blocks = nn.ModuleList([\n",
    "            AdaptLayer(channels=channels, t_embed_dim=t_embed_dim, y_embed_dim=y_embed_dim) for _ in range(num_adapt_layer)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t_embed: torch.Tensor, y_embed: torch.Tensor) -> torch.Tensor:\n",
    "        # x: shape(bs, c, h, w), t_embed: shape(bs, t_embed_dim), y_embed(bs, y_embed_dim)\n",
    "        for block in self.adapt_blocks:\n",
    "            x = block(x, t_embed, y_embed)\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, channels_in: int, channels_out: int, num_adapt_layer: int, t_embed_dim: int, y_embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            nn.Conv2d(in_channels=channels_in, out_channels=channels_out, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.adapt_blocks = nn.ModuleList(\n",
    "            AdaptLayer(channels=channels_out, t_embed_dim=t_embed_dim, y_embed_dim=y_embed_dim) for _ in range(num_adapt_layer)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t_embed: torch.Tensor, y_embed: torch.Tensor) -> torch.Tensor:\n",
    "        # x: shape(bs, c, h, w), t_embed: shape(bs, t_embed_dim), y_embed: shape(bs, y_embed_dim)\n",
    "        x = self.upsample(x)\n",
    "        for block in self.adapt_blocks:\n",
    "            x = block(x, t_embed, y_embed)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a239fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetVectorField(NNVectorField):\n",
    "    def __init__(self, num_channels: int, layer_channels: List[int], num_adapt_layer: int, t_embed_dim: int, y_embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.init_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=num_channels, out_channels=layer_channels[0], kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=layer_channels[0]),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        self.t_embedder = FourierEncoder(dim=t_embed_dim)\n",
    "        self.y_embedder = nn.Embedding(num_embeddings=11, embedding_dim=y_embed_dim)\n",
    "\n",
    "        encoders = []\n",
    "        decoders = []\n",
    "        for (curr, next) in zip(layer_channels[:-1], layer_channels[1:]):\n",
    "            encoders.append(Encoder(channels_in=curr, channels_out=next, num_adapt_layer=num_adapt_layer, t_embed_dim=t_embed_dim, y_embed_dim=y_embed_dim))\n",
    "            decoders.append(Decoder(channels_in=next, channels_out=curr, num_adapt_layer=num_adapt_layer, t_embed_dim=t_embed_dim, y_embed_dim=y_embed_dim))\n",
    "        self.encoders = nn.ModuleList(encoders)\n",
    "        self.decoders = nn.ModuleList(reversed(decoders))\n",
    "\n",
    "        self.midcoder = Midcoder(channels=layer_channels[-1], num_adapt_layer=num_adapt_layer, t_embed_dim=t_embed_dim, y_embed_dim=y_embed_dim)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(in_channels=layer_channels[0], out_channels=num_channels, kernel_size=3, padding=1)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        # x: shape(bs, c, h, w), t: shape(bs, 1, 1, 1), y: shape(bs,)\n",
    "        res = []\n",
    "        t_embed = self.t_embedder(t)\n",
    "        y_embed = self.y_embedder(y)\n",
    "        x = self.init_conv(x)\n",
    "\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x, t_embed, y_embed)\n",
    "            res.append(x.clone())\n",
    "\n",
    "        x = self.midcoder(x, t_embed, y_embed)\n",
    "\n",
    "        for decoder in self.decoders:\n",
    "            x_res = res.pop()\n",
    "            x += x_res\n",
    "            x = decoder(x, t_embed, y_embed)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "\n",
    "        return x     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c52e4",
   "metadata": {},
   "source": [
    "## Part 5: Training Wraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb72287",
   "metadata": {},
   "outputs": [],
   "source": [
    "MiB = 1024 ** 2\n",
    "\n",
    "def model_size_b(model: nn.Module) -> torch.Tensor:\n",
    "    size = 0\n",
    "    for param in model.parameters():\n",
    "        size += param.nelement() * param.element_size()\n",
    "    for buf in model.buffers():\n",
    "        size += buf.nelement() * buf.element_size()\n",
    "    return size\n",
    "\n",
    "class Trainer(ABC):\n",
    "    def __init__(self, model: nn.Module):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_train_loss(self, **kwargs) -> torch.Tensor:\n",
    "        pass\n",
    "\n",
    "    def get_optimizer(self, lr: float):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "    \n",
    "    def train(self, num_epochs: int, device: torch.device, name: str, lr: float=1e-3, **kwargs):\n",
    "        # print the model size\n",
    "        size_b = model_size_b(self.model)\n",
    "        print(f'Training model with size: {size_b / MiB:.3f} MiB')\n",
    "\n",
    "        # start\n",
    "        self.model.to(device)\n",
    "        opt = self.get_optimizer(lr=lr)\n",
    "        self.model.train()\n",
    "        losses = []\n",
    "\n",
    "        # train loop\n",
    "        pbar = tqdm(enumerate(range(num_epochs)))\n",
    "        for idx, epoch in pbar:\n",
    "            opt.zero_grad()\n",
    "            loss = self.get_train_loss(**kwargs)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "            opt.step()\n",
    "            losses.append(loss.item())\n",
    "            pbar.set_description(f'Epoch {idx}, loss: {loss.item():.3f}')\n",
    "        \n",
    "        # finish\n",
    "        self.model.eval()\n",
    "\n",
    "        save_dir = \"./result\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # visualize the loss curve\n",
    "        plt.figure()\n",
    "        plt.plot(losses, label=f\"{name.upper()} Train Loss\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.title(f\"{name.upper()} Loss Curve\")\n",
    "        plt.xlabel(\"epochs\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_dir, f\"{name}_loss.png\"), dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # save the parameters\n",
    "        torch.save(self.model.state_dict(), os.path.join(save_dir, f\"{name}_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8cbc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFGTrainer(Trainer):\n",
    "    def __init__(self, path: ConditionalProbabilityPath, net: CFGVectorField, eta: float, **kwargs):\n",
    "        assert (eta <= 1) and (eta >= 0)\n",
    "        super().__init__(model=net, **kwargs)\n",
    "        self.path = path\n",
    "        self.eta = eta\n",
    "\n",
    "    def get_train_loss(self, batch_size: int) -> torch.Tensor:\n",
    "        z, y = self.path.sample_conditioning_variable(batch_size)   # z: shape(bs, c, h, w), y: shape(bs,)\n",
    "\n",
    "        mask = torch.rand(batch_size).to(y.device)\n",
    "        y[mask < self.eta] = 10.0\n",
    "\n",
    "        t = torch.rand(batch_size, 1, 1, 1).to(y.device)\n",
    "        xt = self.path.sample_conditional_path(z, t)\n",
    "\n",
    "        u_t_ref = self.path.conditional_vector_field(xt, z, t)      # shape(bs, c, h, w)\n",
    "        u_t_theta = self.model(xt, t, y)                              # shape(bs, c, h, w)\n",
    "\n",
    "        error = torch.einsum(\"bchw -> b\", torch.square(u_t_ref - u_t_theta))    # shape(bs, )\n",
    "        return torch.mean(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26548f96",
   "metadata": {},
   "source": [
    "## Part 6: Training, Visualization, and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b9b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_result(net: nn.Module, path: ConditionalProbabilityPath, device: torch.device, name: str):\n",
    "    save_dir = \"./result\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    guidance_scale = [1, 3, 5]\n",
    "    labels = list(range(11))\n",
    "    num_timesteps = 100\n",
    "\n",
    "    for w in guidance_scale:\n",
    "        # calculate the result\n",
    "        x_init, _ = path.p_simple.sample(11)\n",
    "        y = torch.tensor(labels).to(device)\n",
    "        ts = torch.linspace(0, 1, num_timesteps).view(1, -1, 1, 1, 1).expand(11, -1, -1, -1, -1).to(device)\n",
    "        vector_field = CFGVectorField(net=net, guidance_scale=w)\n",
    "        simulator = EulerSimulator(vector_field=vector_field)\n",
    "        x_final = simulator.simulate(x_init, ts, y=y)       # [-1, 1]\n",
    "\n",
    "        # visualization\n",
    "        x_final = (1 + x_final) / 2                         # [0, 1]\n",
    "        grid_image = make_grid(x_final, nrow=11, value_range=(-1, 1)).permute(1, 2, 0).cpu().numpy()\n",
    "        plt.imshow(grid_image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"guidance w: {w}, num_step: {num_timesteps}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_dir, f\"{name}_guidance_w_{w}.png\"), dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "def simple_visualize(net: nn.Module, path: ConditionalProbabilityPath, device: torch.device, label: int, guidance_scale: int, num_steps: int=100):\n",
    "    # calculate the result\n",
    "    vector_field = CFGVectorField(net=net, guidance_scale=guidance_scale)\n",
    "    simulator = EulerSimulator(vector_field=vector_field)\n",
    "    y = torch.tensor([label], dtype=torch.int64).to(device)\n",
    "    x_init, _ = path.p_simple.sample(1)\n",
    "    x_init = x_init.to(device)\n",
    "    ts = torch.linspace(0, 1, num_steps).view(1, -1, 1, 1, 1).to(device)\n",
    "    x_final = simulator.simulate(x_init, ts, y=y)       # [-1, 1]\n",
    "\n",
    "    # visualization\n",
    "    x_final = (1 + x_final) / 2\n",
    "    x_final = x_final.squeeze(dim=0).permute(1, 2, 0).cpu().numpy()\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(x_final)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"guidance w: {guidance_scale}, label: {label}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30081075",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_path = GaussianConditionalProbabilityPath(\n",
    "    p_data = MNISTSampler(),\n",
    "    p_simple_shape = [1, 32, 32],\n",
    "    alpha = LinearAlpha(),\n",
    "    beta = LinearBeta()\n",
    ").to(device)\n",
    "\n",
    "mnist_unet = UNetVectorField(\n",
    "    num_channels = 1,\n",
    "    layer_channels = [32, 64, 128],\n",
    "    num_adapt_layer = 2,\n",
    "    t_embed_dim = 40,\n",
    "    y_embed_dim = 40\n",
    ").to(device)\n",
    "\n",
    "mnist_trainer = CFGTrainer(path=mnist_path, net=mnist_unet, eta=0.1)\n",
    "mnist_trainer.train(num_epochs=10000, device=device, lr=1e-3, name=\"mnist\", batch_size=250)\n",
    "get_train_result(net=mnist_unet, path=mnist_path, device=device, name=\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7845fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_visualize(net=mnist_unet, path=mnist_path, device=device, label=3, guidance_scale=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e827fb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_path = GaussianConditionalProbabilityPath(\n",
    "    p_data = CIFAR10Sampler(),\n",
    "    p_simple_shape = [3, 32, 32],\n",
    "    alpha = LinearAlpha(),\n",
    "    beta = LinearBeta()\n",
    ").to(device)\n",
    "\n",
    "cifar10_unet = UNetVectorField(\n",
    "    num_channels = 3,\n",
    "    layer_channels = [64, 128, 256],\n",
    "    num_adapt_layer = 2,\n",
    "    t_embed_dim = 40,\n",
    "    y_embed_dim = 40\n",
    ").to(device)\n",
    "\n",
    "cifar10_trainer = CFGTrainer(path=cifar10_path, net=cifar10_unet, eta=0.1)\n",
    "cifar10_trainer.train(num_epochs=10000, device=device, lr=1e-4, name=\"cifar10\", batch_size=500)\n",
    "get_train_result(net=cifar10_unet, path=cifar10_path, device=device, name=\"cifar10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca9fa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_visualize(net=cifar10_unet, path=cifar10_path, device=device, label=0, guidance_scale=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
